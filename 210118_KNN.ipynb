GITHUB_RAW_URL = "https://raw.githubusercontent.com/talha-jobaer/KNN_practice/main/data.csv"

DRIVE_PATH = "/content/drive/MyDrive/data.csv"




import pandas as pd
import os

df = None
if GITHUB_RAW_URL:
    try:
        df = pd.read_csv( "https://raw.githubusercontent.com/talha-jobaer/KNN_practice/main/data.csv")
        print("Loaded dataset from GitHub raw URL.")
    except Exception as e:
        print("Failed to load from GitHub URL:", e)

if df is None:

    from google.colab import drive
    drive.mount('/content/drive')
    if os.path.exists(DRIVE_PATH):
        df = pd.read_csv(DRIVE_PATH)
        print("Loaded dataset from Google Drive.")
    else:
        raise FileNotFoundError(f"Could not find file at GitHub or Drive. Please verify GITHUB_RAW_URL or DRIVE_PATH: {DRIVE_PATH}")

print("Shape:", df.shape)
df.head()


print("Columns:", df.columns.tolist())
print("\nDtypes:\n", df.dtypes)
print("\nNull counts:\n", df.isnull().sum())
print("\nValue counts for possible target columns (diagnosis/Outcome):")
for c in ['diagnosis','Diagnosis','Outcome','target','label']:
    if c in df.columns:
        print(f"\n{c}:\n", df[c].value_counts(dropna=False))

display(df.describe().T)



df.columns = [c.strip() for c in df.columns]

df = df.loc[:, ~df.columns.str.contains("^Unnamed")]

possible_targets = ['diagnosis','Diagnosis','Outcome','target','label','class','Class']
target_col = None
for t in possible_targets:
    if t in df.columns:
        target_col = t
        break

if target_col is None:

    raise ValueError("Could not find a target column automatically. Rename the target column to 'diagnosis' or 'Outcome' and re-run.")

print("Detected target column:", target_col)

# Map 'M'/'B' to 1/0 (Breast cancer dataset)
if df[target_col].dtype == object:
    if set(df[target_col].unique()) >= {"M","B"}:
        df[target_col] = df[target_col].map({"M":1,"B":0})
        print("Mapped M/B to 1/0")

# Drop any ID column if present
for id_col in ['id','ID','Id']:
    if id_col in df.columns:
        df = df.drop(columns=[id_col])
        print(f"Dropped column: {id_col}")

print("Final columns:", df.columns.tolist())



from sklearn.model_selection import train_test_split

X = df.drop(columns=[target_col])
y = df[target_col]


X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print("Train:", X_train.shape, "Validation:", X_val.shape, "Test:", X_test.shape)



from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

num_cols = X_train.select_dtypes(include=['int64','float64','int32','float32']).columns.tolist()
cat_cols = X_train.select_dtypes(include=['object','category','bool']).columns.tolist()
print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

num_imputer = SimpleImputer(strategy='median')
scaler = StandardScaler()

X_train_num = X_train[num_cols].copy()
X_val_num   = X_val[num_cols].copy()
X_test_num  = X_test[num_cols].copy()

X_train_num_imp = pd.DataFrame(num_imputer.fit_transform(X_train_num), columns=num_cols, index=X_train_num.index)
X_val_num_imp   = pd.DataFrame(num_imputer.transform(X_val_num), columns=num_cols, index=X_val_num.index)
X_test_num_imp  = pd.DataFrame(num_imputer.transform(X_test_num), columns=num_cols, index=X_test_num.index)

# Scale
X_train_num_scaled = pd.DataFrame(scaler.fit_transform(X_train_num_imp), columns=num_cols, index=X_train_num_imp.index)
X_val_num_scaled   = pd.DataFrame(scaler.transform(X_val_num_imp), columns=num_cols, index=X_val_num_imp.index)
X_test_num_scaled  = pd.DataFrame(scaler.transform(X_test_num_imp), columns=num_cols, index=X_test_num_imp.index)

if cat_cols:
    from sklearn.preprocessing import OneHotEncoder
    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False, drop='first')
    ohe.fit(X_train[cat_cols])
    X_train_cat = pd.DataFrame(ohe.transform(X_train[cat_cols]), index=X_train.index, columns=ohe.get_feature_names_out(cat_cols))
    X_val_cat   = pd.DataFrame(ohe.transform(X_val[cat_cols]), index=X_val.index, columns=ohe.get_feature_names_out(cat_cols))
    X_test_cat  = pd.DataFrame(ohe.transform(X_test[cat_cols]), index=X_test.index, columns=ohe.get_feature_names_out(cat_cols))

    X_train_proc = pd.concat([X_train_num_scaled, X_train_cat], axis=1)
    X_val_proc   = pd.concat([X_val_num_scaled, X_val_cat], axis=1)
    X_test_proc  = pd.concat([X_test_num_scaled, X_test_cat], axis=1)
else:
    X_train_proc = X_train_num_scaled
    X_val_proc   = X_val_num_scaled
    X_test_proc  = X_test_num_scaled

print("Processed shapes:", X_train_proc.shape, X_val_proc.shape, X_test_proc.shape)
display(X_train_proc.head())


from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='minkowski')
knn.fit(X_train_proc, y_train)

y_val_pred = knn.predict(X_val_proc)
y_val_prob = knn.predict_proba(X_val_proc)[:,1]

print("Baseline KNN (k=5) on Validation:")
print("Accuracy:", accuracy_score(y_val, y_val_pred))
print("Precision:", precision_score(y_val, y_val_pred))
print("Recall:", recall_score(y_val, y_val_pred))
print("F1:", f1_score(y_val, y_val_pred))
print("AUC (val):", roc_auc_score(y_val, y_val_prob))


import matplotlib.pyplot as plt
k_values = list(range(1,31))
val_scores = []
for k in k_values:
    m = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='minkowski')
    m.fit(X_train_proc, y_train)
    val_scores.append(accuracy_score(y_val, m.predict(X_val_proc)))

plt.figure(figsize=(10,5))
plt.plot(k_values, val_scores, marker='o')
plt.xticks(k_values)
plt.xlabel('k (number of neighbors)')
plt.ylabel('Validation Accuracy')
plt.title('Elbow Plot / Accuracy vs k (Validation set)')
best_k = k_values[int(pd.Series(val_scores).idxmax())]
plt.axvline(best_k, color='red', linestyle='--', label=f'Best k on val={best_k}')
plt.legend()
plt.grid(True)
plt.show()
print("Best k on validation:", best_k, "with accuracy", max(val_scores))


from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV

pipe = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('knn', KNeighborsClassifier())
])

param_grid = {
    'knn__n_neighbors': [3,5,7,9,11],
    'knn__weights': ['uniform', 'distance'],
    'knn__metric': ['minkowski', 'euclidean', 'manhattan'],
    'knn__p': [2,1]
}

grid = GridSearchCV(pipe, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)
grid.fit(X_train, y_train)

print("Best params (from GridSearch on TRAIN):", grid.best_params_)
print("Best CV AUC:", grid.best_score_)
best_grid = grid.best_estimator_


y_val_pred_best = best_grid.predict(X_val)
y_val_prob_best = best_grid.predict_proba(X_val)[:,1]
from sklearn.metrics import classification_report
print("Validation Metrics (best_grid):")
print(classification_report(y_val, y_val_pred_best))
print("AUC (val):", roc_auc_score(y_val, y_val_prob_best))

import numpy as np
X_trainval = pd.concat([X_train, X_val], axis=0)
y_trainval = pd.concat([y_train, y_val], axis=0)

best_params = grid.best_params_
final_pipe = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('knn', KNeighborsClassifier(**{k.split('__')[-1]: v for k,v in best_params.items() if k.startswith('knn__')}))
])
final_pipe.fit(X_trainval, y_trainval)

y_test_pred = final_pipe.predict(X_test)
y_test_prob = final_pipe.predict_proba(X_test)[:,1]

print("Final Test Metrics (after refit on Train+Val):")
print(classification_report(y_test, y_test_pred))
print("AUC (test):", roc_auc_score(y_test, y_test_prob))


from sklearn.metrics import confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', linewidths=0.5)
plt.title("Confusion Matrix - Final KNN (Test)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

fpr, tpr, _ = roc_curve(y_test, y_test_prob)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(7,5))
plt.plot(fpr, tpr, label=f'Final KNN (AUC={roc_auc:.3f})')
plt.plot([0,1],[0,1],'k--', linewidth=1)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Final KNN (Test)')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
print("Test Accuracy:", accuracy_score(y_test, y_test_pred))
print("Test Precision:", precision_score(y_test, y_test_pred))
print("Test Recall:", recall_score(y_test, y_test_pred))
print("Test F1:", f1_score(y_test, y_test_pred))
print("Test AUC:", roc_auc)


from sklearn.decomposition import PCA
import numpy as np

X_test_processed_for_plot = final_pipe.named_steps['scaler'].transform(
    pd.DataFrame(final_pipe.named_steps['imputer'].transform(X_test), columns=X_test.columns)
)

X_trainval_processed = final_pipe.named_steps['scaler'].transform(
    pd.DataFrame(final_pipe.named_steps['imputer'].transform(X_trainval), columns=X_trainval.columns)
)

pca = PCA(n_components=2, random_state=42)
pca.fit(X_trainval_processed)
X_test_pca = pca.transform(X_test_processed_for_plot)
X_trainval_pca = pca.transform(X_trainval_processed)

knn_vis = KNeighborsClassifier(n_neighbors=final_pipe.named_steps['knn'].n_neighbors,
                               weights=final_pipe.named_steps['knn'].weights,
                               metric=final_pipe.named_steps['knn'].metric,
                               p=final_pipe.named_steps['knn'].p if hasattr(final_pipe.named_steps['knn'],'p') else 2)
knn_vis.fit(X_trainval_pca, y_trainval)

x_min, x_max = X_trainval_pca[:,0].min()-1, X_trainval_pca[:,0].max()+1
y_min, y_max = X_trainval_pca[:,1].min()-1, X_trainval_pca[:,1].max()+1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300), np.linspace(y_min, y_max, 300))
grid = np.c_[xx.ravel(), yy.ravel()]
Z = knn_vis.predict(grid)
Z = Z.reshape(xx.shape)

plt.figure(figsize=(10,7))
plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')
plt.scatter(X_test_pca[:,0], X_test_pca[:,1], c=y_test, cmap='coolwarm', edgecolor='k', s=70)
plt.title("2D Decision Boundary (KNN) using PCA projection of features")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()



import joblib
# Save to notebook working dir
joblib.dump(final_pipe, "final_knn_pipeline.pkl")
#print("Saved final pipeline to 'final_knn_pipeline.pkl'. Upload this and your notebook/data.csv to your GitHub repo for submission.")


